"""
api_fastapi.py â€” Tupick RAG (FastAPI ë°±ì—”ë“œ) - SQLite + Email Auth í†µí•©
===========================================
ê¸°ëŠ¥:
- SQLite ë°ì´í„°ë² ì´ìŠ¤ë¡œ ì‚¬ìš©ì ê´€ë¦¬
- ì´ë©”ì¼ íšŒì›ê°€ì…/ë¡œê·¸ì¸
- Google OAuth ë¡œê·¸ì¸
- OpenAI GPT ì‚¬ìš©
- JWT í† í° ì¸ì¦
"""

from __future__ import annotations
import os
import re
import json
import uuid
import sqlite3
import secrets
import smtplib
import redis
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart
from typing import List, Dict, Any, Tuple, Optional
from datetime import datetime, timedelta
from contextlib import contextmanager
from collections import defaultdict
from datetime import datetime
from typing import List, Dict

import time 
import numpy as np
import faiss
import requests
from bs4 import BeautifulSoup

from fastapi import FastAPI, HTTPException, Depends, status, Request
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, HTMLResponse, RedirectResponse, Response, FileResponse
from fastapi.security import HTTPBearer
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel, Field, EmailStr
from dotenv import load_dotenv
from jose import JWTError, jwt
from passlib.context import CryptContext
from authlib.integrations.starlette_client import OAuth
from starlette.middleware.sessions import SessionMiddleware
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ===== ì„¤ì • =====
JWT_SECRET_KEY = os.getenv("JWT_SECRET_KEY", "")
JWT_ALGORITHM = "HS256"
JWT_EXPIRE_MINUTES = 1440  # 24ì‹œê°„

# OpenAI ì„¤ì •
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
OPENAI_MODEL = os.getenv("OPENAI_MODEL", "gpt-4o-mini")

# SMTP ì„¤ì • (ì´ë©”ì¼ ì¸ì¦ìš©)
SMTP_SERVER = os.getenv("SMTP_SERVER", "smtp.gmail.com")
SMTP_PORT = int(os.getenv("SMTP_PORT", 587))
SMTP_EMAIL = os.getenv("SMTP_EMAIL", "")
SMTP_PASSWORD = os.getenv("SMTP_PASSWORD", "")

# ì¸ì¦ ì½”ë“œ ì €ì¥ (ë©”ëª¨ë¦¬)
verification_codes = {}

# Google OAuth ì„¤ì •
GOOGLE_CLIENT_ID = os.getenv("GOOGLE_CLIENT_ID", "")
GOOGLE_CLIENT_SECRET = os.getenv("GOOGLE_CLIENT_SECRET", "")
GOOGLE_REDIRECT_URI = os.getenv("GOOGLE_REDIRECT_URI", "http://localhost:8000/auth/google/callback")

# ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
DB_PATH = os.getenv("DB_PATH", "./tupick.db")

# RAG ì„¤ì •
EMB_MODEL_NAME = os.getenv("EMB_MODEL_NAME", "BAAI/bge-m3")
TOP_K = int(os.getenv("TOP_K", 5))
CHUNK_SIZE = 550
CHUNK_OVERLAP = 60

# Redis ì„¤ì •
REDIS_URL = os.getenv("REDIS_URL", "redis://localhost:8000")
redis_client = redis.Redis.from_url(REDIS_URL, decode_responses=True)

# ë¹„ë°€ë²ˆí˜¸ ì•”í˜¸í™”
pwd_context = CryptContext(schemes=["argon2"], deprecated="auto")

# OAuth ì„¤ì •
oauth = OAuth()
if GOOGLE_CLIENT_ID and GOOGLE_CLIENT_SECRET:
    oauth.register(
        name='google',
        client_id=GOOGLE_CLIENT_ID,
        client_secret=GOOGLE_CLIENT_SECRET,
        server_metadata_url="https://accounts.google.com/.well-known/openid-configuration",
        client_kwargs={
            'scope': 'openid email profile',
            'redirect_uri': GOOGLE_REDIRECT_URI
        }
    )

# ===== ë°ì´í„°ë² ì´ìŠ¤ ê´€ë¦¬ =====

@contextmanager
def get_db():
    """SQLite ì—°ê²° ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €"""
    conn = sqlite3.connect(DB_PATH, check_same_thread=False)
    conn.row_factory = sqlite3.Row
    try:
        yield conn
    finally:
        conn.close()

def init_db():
    """ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™”"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # ì‚¬ìš©ì í…Œì´ë¸”
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS users (
            id TEXT PRIMARY KEY,
            email TEXT UNIQUE NOT NULL,
            name TEXT NOT NULL,
            hashed_password TEXT,
            auth_type TEXT DEFAULT 'email',
            picture TEXT,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP,
            updated_at TEXT DEFAULT CURRENT_TIMESTAMP
        )
        ''')
        
        # í”„ë¡œí•„ í…Œì´ë¸”
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS user_profiles (
            user_id TEXT PRIMARY KEY,
            risk TEXT DEFAULT 'ì¤‘ê°„',
            budget INTEGER DEFAULT 1000000,
            goal TEXT DEFAULT 'ë‹¨ê¸°í˜„ê¸ˆíë¦„',
            interest_field TEXT DEFAULT 'ë¶€ë™ì‚°, ì˜ˆìˆ , ìŒì•…',
            experience_level TEXT DEFAULT 'ì´ˆë³´ì',
            FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
        )
        ''')
        
        # ë¬¸ì„œ í…Œì´ë¸”
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS documents (
            id TEXT PRIMARY KEY,
            user_id TEXT,
            source TEXT,
            category TEXT,
            title TEXT,
            section TEXT,
            url TEXT,
            as_of_date TEXT,
            text TEXT,
            language TEXT DEFAULT 'ko-KR',
            created_at TEXT DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE SET NULL
        )
        ''')
        
        # ì±„íŒ… íˆìŠ¤í† ë¦¬
        cursor.execute('''
        CREATE TABLE IF NOT EXISTS chat_history (
            id TEXT PRIMARY KEY,
            user_id TEXT,
            question TEXT,
            answer TEXT,
            created_at TEXT DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (user_id) REFERENCES users(id) ON DELETE CASCADE
        )
        ''')
        
        # ì¸ë±ìŠ¤ ìƒì„±
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_users_email ON users(email)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_docs_user ON documents(user_id)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_chat_user ON chat_history(user_id)')
        
        conn.commit()
        print("âœ… Database initialized!")

# ===== Pydantic ëª¨ë¸ =====

def now_date() -> str:
    return datetime.now().strftime("%Y-%m-%d")

class User(BaseModel):
    id: str
    email: str
    name: str
    auth_type: str = "email"
    picture: Optional[str] = None
    created_at: str = Field(default_factory=now_date)

class UserCreate(BaseModel):
    email: EmailStr
    password: str
    name: str

class UserLogin(BaseModel):
    email: EmailStr
    password: str

class Token(BaseModel):
    access_token: str
    token_type: str
    user: User

class UserProfile(BaseModel):
    risk: str = "ì¤‘ê°„"
    budget: int = 1_000_000
    goal: str = "ë‹¨ê¸°í˜„ê¸ˆíë¦„"
    interest_field: str = "ë¶€ë™ì‚°, ì˜ˆìˆ , ìŒì•…"
    experience_level: str = "ì´ˆë³´ì"

class DocChunk(BaseModel):
    id: str
    source: str
    category: str
    title: str
    section: str
    url: str
    as_of_date: str
    text: str
    language: str = "ko-KR"

class IngestReq(BaseModel):
    urls: List[str]
    source: str = "generic"
    use_js: bool = False

class QueryReq(BaseModel):
    question: str
    risk: str = "ì¤‘ê°„"
    budget: int = 1_000_000
    goal: str = "ë‹¨ê¸°í˜„ê¸ˆíë¦„"
    k: int = 5
    use_profile: bool = True

class QueryRes(BaseModel):
    answer: str
    backend: str
    k: int
    sources: List[Dict[str, Any]]

class ChatMessage(BaseModel):
    role: str  # "user" or "bot"
    content: str
    timestamp: str

class ChatSession(BaseModel):
    id: str
    user_email: str
    timestamp: str
    messages: List[ChatMessage]

class SaveChatRequest(BaseModel):
    messages: List[ChatMessage]

# ===== ì‚¬ìš©ì ê´€ë¦¬ í•¨ìˆ˜ =====

def get_user_by_email(email: str) -> Optional[Dict]:
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM users WHERE email = ?", (email,))
        row = cursor.fetchone()
        return dict(row) if row else None

def create_user(user_data: UserCreate) -> User:
    user_id = str(uuid.uuid4())
    
    # SHA-256 pre-hashingìœ¼ë¡œ 72ë°”ì´íŠ¸ ì œí•œ ì™„ì „íˆ ì œê±°
    prepared_password = _prepare_password_for_bcrypt(user_data.password)
    hashed_pw = pwd_context.hash(prepared_password)
    
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
        INSERT INTO users (id, email, name, hashed_password, auth_type)
        VALUES (?, ?, ?, ?, 'email')
        ''', (user_id, user_data.email, user_data.name, hashed_pw))
        
        # ê¸°ë³¸ í”„ë¡œí•„ ìƒì„±
        cursor.execute('INSERT INTO user_profiles (user_id) VALUES (?)', (user_id,))
        conn.commit()
    
    return User(
        id=user_id,
        email=user_data.email,
        name=user_data.name,
        auth_type="email"
    )

def create_oauth_user(email: str, name: str, picture: str = None) -> User:
    """OAuth ì‚¬ìš©ì ìƒì„±"""
    user_id = str(uuid.uuid4())
    
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
        INSERT INTO users (id, email, name, auth_type, picture)
        VALUES (?, ?, ?, 'google', ?)
        ''', (user_id, email, name, picture))
        
        cursor.execute('INSERT INTO user_profiles (user_id) VALUES (?)', (user_id,))
        conn.commit()
    
    return User(
        id=user_id,
        email=email,
        name=name,
        auth_type="google",
        picture=picture
    )

# ===== ë¹„ë°€ë²ˆí˜¸ ê´€ë¦¬ =====

def _prepare_password_for_bcrypt(password: str) -> str:
    """
    ë¹„ë°€ë²ˆí˜¸ë¥¼ bcryptë¡œ í•´ì‹±í•˜ê¸° ì „ì— SHA-256ìœ¼ë¡œ pre-hash
    ì´ë ‡ê²Œ í•˜ë©´ 72ë°”ì´íŠ¸ ì œí•œì„ ì™„ì „íˆ ìš°íšŒí•˜ë©´ì„œë„ ë³´ì•ˆì„± ìœ ì§€
    """
    import hashlib
    # SHA-256 í•´ì‹œ (í•­ìƒ 64ìì˜ hex ë¬¸ìì—´ ë°˜í™˜)
    return hashlib.sha256(password.encode('utf-8')).hexdigest()

def verify_password(plain_password: str, hashed_password: str) -> bool:
    """ë¹„ë°€ë²ˆí˜¸ ê²€ì¦ (pre-hashing ì ìš©)"""
    prepared_password = _prepare_password_for_bcrypt(plain_password)
    return pwd_context.verify(prepared_password, hashed_password)

def validate_password_strength(password: str) -> Tuple[bool, str]:
    if len(password) < 8:
        return False, "ë¹„ë°€ë²ˆí˜¸ëŠ” ìµœì†Œ 8ì ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤"
    if len(password) > 20:
        return False, "ë¹„ë°€ë²ˆí˜¸ëŠ” ìµœëŒ€ 20ìê¹Œì§€ ê°€ëŠ¥í•©ë‹ˆë‹¤"
    
    # ëŒ€ë¬¸ì, ì†Œë¬¸ì, ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì ì²´í¬
    has_lower = bool(re.search(r"[a-z]", password))
    has_upper = bool(re.search(r"[A-Z]", password))
    has_digit = bool(re.search(r"\d", password))
    has_special = bool(re.search(r"[!@#$%^&*(),.?\":{}|<>]", password))
    
    # 4ê°€ì§€ ì¤‘ 2ê°€ì§€ ì´ìƒ í¬í•¨ í™•ì¸
    count = sum([has_lower, has_upper, has_digit, has_special])
    if count < 2:
        return False, "ë¹„ë°€ë²ˆí˜¸ëŠ” ëŒ€ë¬¸ì, ì†Œë¬¸ì, ìˆ«ì, íŠ¹ìˆ˜ë¬¸ì ì¤‘ 2ê°€ì§€ ì´ìƒì„ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤"
    
    return True, "OK"

# ===== JWT í† í° ê´€ë¦¬ =====

login_attempts = defaultdict(list)

def check_rate_limit(email: str, max_attempts: int = 5, window_minutes: int = 15):
    now = datetime.now()
    attempts = login_attempts[email]
    attempts = [t for t in attempts if now - t < timedelta(minutes=window_minutes)]
    login_attempts[email] = attempts
    
    if len(attempts) >= max_attempts:
        raise HTTPException(
            status_code=429,
            detail=f"ë„ˆë¬´ ë§ì€ ë¡œê·¸ì¸ ì‹œë„. {window_minutes}ë¶„ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”"
        )
    attempts.append(now)

def create_access_token(data: dict) -> str:
    to_encode = data.copy()
    expire = datetime.utcnow() + timedelta(minutes=JWT_EXPIRE_MINUTES)
    to_encode.update({"exp": expire})
    return jwt.encode(to_encode, JWT_SECRET_KEY, algorithm=JWT_ALGORITHM)

security = HTTPBearer()

async def get_current_user(token: str = Depends(security)) -> User:
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="ì¸ì¦ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤",
        headers={"WWW-Authenticate": "Bearer"},
    )
    try:
        payload = jwt.decode(token.credentials, JWT_SECRET_KEY, algorithms=[JWT_ALGORITHM])
        email: str = payload.get("sub")
        if email is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception
    
    user_dict = get_user_by_email(email)
    if user_dict is None:
        raise credentials_exception
    
    return User(**{k: v for k, v in user_dict.items() if k != "hashed_password"})

# ===== RAG ê´€ë ¨ í•¨ìˆ˜ë“¤ =====

_embedder: Optional[SentenceTransformer] = None
_index: Optional[faiss.IndexFlatIP] = None
_texts: List[str] = []
_metas: List[Dict[str, Any]] = []
_bm25: Optional[BM25Okapi] = None

def get_embedder() -> SentenceTransformer:
    global _embedder
    if _embedder is None:
        _embedder = SentenceTransformer(EMB_MODEL_NAME)
    return _embedder

def normalize_ws(s: str) -> str:
    return re.sub(r"\s+", " ", s or "").strip()

def chunk_text(text: str, size: int = CHUNK_SIZE, overlap: int = CHUNK_OVERLAP) -> List[str]:
    toks = normalize_ws(text).split(" ")
    out, i = [], 0
    while i < len(toks):
        out.append(" ".join(toks[i:i + size]))
        i += max(1, size - overlap)
    return [c for c in out if len(c) > 20]

def encode_texts(texts: List[str]) -> np.ndarray:
    emb = get_embedder()
    vecs = emb.encode(texts, normalize_embeddings=True)
    return np.array(vecs, dtype="float32")

def build_index(vectors: np.ndarray) -> faiss.IndexFlatIP:
    faiss.normalize_L2(vectors)
    index = faiss.IndexFlatIP(vectors.shape[1])
    index.add(vectors)
    return index

def vec_search(query: str, k: int) -> List[int]:
    if _index is None or not _texts:
        return []
    qv = encode_texts([query])
    faiss.normalize_L2(qv)
    scores, idxs = _index.search(qv, max(k, 8))
    return idxs[0].tolist()

def bm25_rerank(query: str, candidates: List[int], k: int) -> List[int]:
    if not candidates or _bm25 is None:
        return candidates[:k]
    scores = _bm25.get_scores(query.split())
    pairs = [(i, float(scores[i])) for i in candidates]
    pairs.sort(key=lambda x: x[1], reverse=True)
    return [i for i, _ in pairs[:k]]

def fetch_url(url: str, timeout: int = 20, use_js: bool = False) -> Tuple[str, str]:
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
        "Accept-Language": "ko,ko-KR;q=0.9",
    }
    r = requests.get(url, headers=headers, timeout=timeout)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")
    title = soup.title.text.strip() if soup.title else url
    for t in soup(["script", "style", "noscript"]):
        t.extract()
    body = normalize_ws(soup.get_text(" "))
    return title, body

'''
def call_openai(prompt: str, system: str) -> str:
    if not OPENAI_API_KEY:
        raise HTTPException(400, "OpenAI API key not configured")
    
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": OPENAI_MODEL,
        "messages": [
            {"role": "system", "content": system},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.2
    }
    r = requests.post("https://api.openai.com/v1/chat/completions", 
                     headers=headers, json=payload, timeout=120)
    r.raise_for_status()
    return r.json()["choices"][0]["message"]["content"]
'''
def call_openai(prompt: str, system: str) -> str:
    if not OPENAI_API_KEY:
        raise HTTPException(400, "OpenAI API key not configured")
    
    headers = {
        "Authorization": f"Bearer {OPENAI_API_KEY}",
        "Content-Type": "application/json"
    }
    payload = {
        "model": OPENAI_MODEL,
        "messages": [
            {"role": "system", "content": system},
            {"role": "user", "content": prompt}
        ],
        "temperature": 0.2
    }
    
    # Retry ë¡œì§ (429 ì—ëŸ¬ ëŒ€ì‘)
    max_retries = 3
    for attempt in range(max_retries):
        try:
            r = requests.post(
                "https://api.openai.com/v1/chat/completions", 
                headers=headers, 
                json=payload, 
                timeout=120
            )
            r.raise_for_status()
            return r.json()["choices"][0]["message"]["content"]
            
        except requests.exceptions.HTTPError as e:
            if e.response.status_code == 429:
                if attempt < max_retries - 1:
                    wait_time = (attempt + 1) * 15  # 15ì´ˆ, 30ì´ˆ, 45ì´ˆ
                    print(f"âš ï¸ OpenAI Rate limit. Waiting {wait_time}s...")
                    time.sleep(wait_time)
                    continue
                else:
                    # ìµœì¢… ì‹¤íŒ¨ ì‹œ ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•œ ë©”ì‹œì§€
                    raise HTTPException(
                        status_code=429,
                        detail="OpenAI API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. 1ë¶„ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
                    )
            else:
                # ë‹¤ë¥¸ HTTP ì—ëŸ¬ëŠ” ê·¸ëŒ€ë¡œ ì „ë‹¬
                raise HTTPException(
                    status_code=e.response.status_code,
                    detail=f"OpenAI API ì˜¤ë¥˜: {e.response.text}"
                )
                
        except requests.exceptions.Timeout:
            raise HTTPException(408, "OpenAI API ì‘ë‹µ ì‹œê°„ ì´ˆê³¼")
            
        except Exception as e:
            raise HTTPException(500, f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")

LLM_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ 'ì¡°ê°íˆ¬ì ì „ë¬¸ ìƒë‹´ AI'ì…ë‹ˆë‹¤.  
ì‚¬ìš©ìëŠ” ë¶€ë™ì‚°, ë¯¸ìˆ í’ˆ, ìŒì›ì €ì‘ê¶Œ ë“± ë‹¤ì–‘í•œ ëŒ€ì²´ìì‚°ì— ëŒ€í•œ ì¡°ê°íˆ¬ì ê´€ë ¨ ì§ˆë¬¸ì„ í•©ë‹ˆë‹¤.  
ë‹¹ì‹ ì˜ ì—­í• ì€ ì¡°ê°íˆ¬ì ì‹œì¥ê³¼ í”Œë«í¼ì— ëŒ€í•œ ê°ê´€ì Â·ì •ë³´ ì¤‘ì‹¬ì˜ ì„¤ëª…ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

---
### ğŸ”¹ë‹µë³€ ê·œì¹™
1. **ì •í™•ì„±** â€” ì œê³µëœ ìë£Œì™€ ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì§„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹ ë¢°ì„± ìˆê²Œ ë‹µë³€í•©ë‹ˆë‹¤.  
2. **ì „ë¬¸ì„±** â€” ì¡°ê°íˆ¬ì ê´€ë ¨ ìš©ì–´(ìˆ˜ìµì¦ê¶Œ, ì§€ë¶„ê±°ë˜, í™˜ê¸ˆì„± ë“±)ë¥¼ ìì—°ìŠ¤ëŸ½ê²Œ í™œìš©í•©ë‹ˆë‹¤.  
3. **ë§¥ë½ í•´ì„** â€” ì¡°ê°íˆ¬ìì™€ ì§ì ‘ ê´€ë ¨ ì—†ëŠ” ì§ˆë¬¸ë„ ì¡°ê°íˆ¬ì ê´€ì ì—ì„œ ì¬í•´ì„í•©ë‹ˆë‹¤.  
4. **ì¤‘ë¦½ì„± ìœ ì§€** â€” íˆ¬ì ê¶Œìœ ë‚˜ ì¶”ì²œì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ("~í•˜ì„¸ìš”" ëŒ€ì‹  "~í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")  
5. **ì‹¤ìš©ì„±** â€” ì¼ë°˜ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ ë°©ì‹ìœ¼ë¡œ ì„¤ëª…í•©ë‹ˆë‹¤.  
6. **ë©´ì±… ë¬¸êµ¬** â€” ëª¨ë“  ë‹µë³€ ë§ˆì§€ë§‰ì— ì•„ë˜ ë¬¸êµ¬ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•©ë‹ˆë‹¤.  
   > "ë³¸ ì„œë¹„ìŠ¤ëŠ” ì •ë³´ ì œê³µìš©ì´ë©°, ìˆ˜ìµ ë³´ì¥ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

---
### ğŸ”¹í•œêµ­ì˜ ì£¼ìš” ì¡°ê°íˆ¬ì í”Œë«í¼
ì•„ë˜ ëª©ë¡ì€ ì°¸ê³ ìš©ì´ë©°, íŠ¹ì • í”Œë«í¼ì„ ì¶”ì²œí•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

#### ğŸ’¼ ë¶€ë™ì‚° ì¡°ê°íˆ¬ì
- **KASA(ì¹´ì‚¬)** â€” ìƒì—…ìš© ë¹Œë”© ê¸°ë°˜ì˜ ìˆ˜ìµì¦ê¶Œ íˆ¬ì í”Œë«í¼  
- **Funble(í€ë¸”)** â€” ë””ì§€í„¸ ìˆ˜ìµì¦ê¶Œ(STO) ê¸°ë°˜ ë¶€ë™ì‚° ì¡°ê°íˆ¬ì í”Œë«í¼  
- **ë£¨ì„¼íŠ¸ë¸”ë¡(LucentBlock)** â€” Sou.place ë¸Œëœë“œë¡œ ë¶€ë™ì‚° ì§€ë¶„í™” íˆ¬ì ì„œë¹„ìŠ¤ ìš´ì˜

#### ğŸ¨ ë¯¸ìˆ í’ˆ ì¡°ê°íˆ¬ì
- **TESSA(í…Œì‚¬)** â€” ë¯¸ìˆ í’ˆ ì§€ë¶„ íˆ¬ì ë° ë¸”ë¡ì²´ì¸ ê±°ë˜ ê¸°ìˆ  í™œìš©  
- **Art & Guide(ì•„íŠ¸ì•¤ê°€ì´ë“œ, ì—´ë§¤ì»´í¼ë‹ˆ)** â€” ê³ ê°€ ë¯¸ìˆ ì‘í’ˆ ê³µë™íˆ¬ìí˜• ì„œë¹„ìŠ¤  
- **SOTWO(ì„œìš¸ì˜¥ì…˜ë¸”ë£¨)** â€” ë¯¸ìˆ ì‹œì¥ê³¼ ê²½ë§¤ ì—°ê³„í˜• ì¡°ê°íˆ¬ì ëª¨ë¸

#### ğŸµ ì €ì‘ê¶ŒÂ·ì—”í„°í…Œì¸ë¨¼íŠ¸ ì¡°ê°íˆ¬ì
- **ë®¤ì§ì¹´ìš°(Musicow)** â€” ìŒì› ì €ì‘ê¶Œë£Œ ìˆ˜ìµì„ ê¸°ë°˜ìœ¼ë¡œ í•œ ì¡°ê°íˆ¬ì  
- **WEA(ìœ„ì•„)** â€” ê³µì—° IP ë° ì½˜í…ì¸  ì €ì‘ê¶Œ íˆ¬ìí˜• í”Œë«í¼

#### âš™ï¸ ê¸°íƒ€ ëŒ€ì²´ìì‚° ê¸°ë°˜
- **í”¼ìŠ¤(Piece)** â€” ëª…í’ˆÂ·í•œì •íŒ ìŠ¤ë‹ˆì»¤ì¦ˆ ë“± ì‹¤ë¬¼ìì‚° ì¡°ê°íˆ¬ì  
- **ì†Œíˆ¬(SOTWO)** â€” ì‹¤ë¬¼ ì˜ˆìˆ í’ˆ ë° í•œì •íŒ ì»¬ë ‰í„°ë¸” ì¤‘ì‹¬ íˆ¬ì  
- **Pica(í”¼ì¹´)** â€” ì˜ˆìˆ  ë° ì»¬ë ‰í„°ë¸” ìì‚°ì˜ í† í°í™” íˆ¬ì í”Œë«í¼

---
### ğŸ”¹ë‹µë³€ í†¤ & ìŠ¤íƒ€ì¼
- ê²©ì‹ ìˆê³  ì‹ ë¢°ê° ìˆëŠ” ì–´ì¡° ì‚¬ìš©  
- ê¸°ìˆ ì  ìš©ì–´ë‚˜ ê¸ˆìœµ ìš©ì–´ëŠ” ê°€ëŠ¥í•œ í•œ í’€ì–´ì„œ ì„¤ëª…  
- í”Œë«í¼ ê°„ ë¹„êµë¥¼ ìš”ì²­ë°›ì„ ê²½ìš°, ì¥ë‹¨ì ì„ ê· í˜• ìˆê²Œ ê¸°ìˆ   
- ì‚¬ìš©ìì˜ íˆ¬ì íŒë‹¨ì„ ëŒ€ì‹ í•˜ì§€ ì•Šê³ , ì •ë³´ ì „ë‹¬ì— ì§‘ì¤‘  

---
### ğŸ”¹ë©´ì±… ì¡°í•­ (ëª¨ë“  ë‹µë³€ ë§ˆì§€ë§‰ì— í¬í•¨)
> ë³¸ ì„œë¹„ìŠ¤ëŠ” ì •ë³´ ì œê³µìš©ì´ë©°, ìˆ˜ìµ ë³´ì¥ì„ í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
"""

def build_user_prompt(question: str, passages: List[Dict[str, Any]], 
                     risk: str, budget: int, goal: str) -> str:
    ctx_lines = []
    for i, p in enumerate(passages, start=1):
        ctx_lines.append(f"[{i}] {p.get('title', '')} | {p.get('url', '')}\n{p.get('text', '')}")
    context = "\n\n".join(ctx_lines)
    return (
        f"[ì‚¬ìš©ì ì„±í–¥]\në¦¬ìŠ¤í¬={risk}, ì˜ˆì‚°={budget}ì›, ëª©í‘œ={goal}\n\n"
        # f"[ì§ˆë¬¸]\n{question}\n\n[CONTEXT]\n{context}\n"
    )

# ===== FastAPI ì•± =====

app = FastAPI(title="Tupick RAG API with SQLite Auth", version="1.0.0")

app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
app.add_middleware(SessionMiddleware, secret_key=JWT_SECRET_KEY)
app.mount("/static", StaticFiles(directory="."), name="static")

@app.get("/capstone.mp4")
async def get_video():
    return FileResponse("capstone.mp4", media_type="video/mp4")

@app.on_event("startup")
def startup():
    global _texts, _metas, _index, _bm25
    init_db()
    
    # ê¸°ì¡´ ë¬¸ì„œ ë¡œë“œ (ìˆìœ¼ë©´)
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM documents")
        rows = cursor.fetchall()
        if rows:
            _texts = [dict(r)["text"] for r in rows]
            _metas = [{k: dict(r)[k] for k in ["id", "title", "url", "as_of_date", "source", "category"]} 
                     for r in rows]
            if _texts:
                _bm25 = BM25Okapi([t.split() for t in _texts])
                vecs = encode_texts(_texts)
                _index = build_index(vecs)

# ===== ì¸ì¦ API =====

def generate_verification_code() -> str:
    """4ìë¦¬ ì¸ì¦ ì½”ë“œ ìƒì„±"""
    return ''.join([str(secrets.randbelow(10)) for _ in range(4)])

def send_verification_email(email: str, code: str) -> bool:
    """ì¸ì¦ ì½”ë“œ ì´ë©”ì¼ ë°œì†¡"""
    if not SMTP_EMAIL or not SMTP_PASSWORD:
        print(f"ğŸ“§ [ê°œë°œ ëª¨ë“œ] ì¸ì¦ ì½”ë“œ: {email} -> {code}")
        return True
    
    try:
        msg = MIMEMultipart()
        msg['From'] = SMTP_EMAIL
        msg['To'] = email
        msg['Subject'] = '[Tupick] ì´ë©”ì¼ ì¸ì¦ ì½”ë“œ'
        
        body = f"""ì•ˆë…•í•˜ì„¸ìš”, Tupickì…ë‹ˆë‹¤.

íšŒì›ê°€ì…ì„ ìœ„í•œ ì¸ì¦ ì½”ë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:

ì¸ì¦ ì½”ë“œ: {code}

ì´ ì½”ë“œëŠ” 10ë¶„ê°„ ìœ íš¨í•©ë‹ˆë‹¤.

ê°ì‚¬í•©ë‹ˆë‹¤.
Tupick íŒ€"""
        
        msg.attach(MIMEText(body, 'plain', 'utf-8'))
        
        server = smtplib.SMTP(SMTP_SERVER, SMTP_PORT)
        server.starttls()
        server.login(SMTP_EMAIL, SMTP_PASSWORD)
        server.send_message(msg)
        server.quit()
        
        return True
    except Exception as e:
        print(f"âŒ ì´ë©”ì¼ ë°œì†¡ ì‹¤íŒ¨: {e}")
        return False

class VerificationRequest(BaseModel):
    email: EmailStr

@app.post("/auth/send-verification")
async def send_verification_code(req: VerificationRequest):
    """ì´ë©”ì¼ ì¸ì¦ ì½”ë“œ ë°œì†¡"""
    if get_user_by_email(req.email):
        raise HTTPException(400, "ì´ë¯¸ ë“±ë¡ëœ ì´ë©”ì¼ì…ë‹ˆë‹¤")
    
    code = generate_verification_code()
    
    verification_codes[req.email] = {
        "code": code,
        "expires_at": datetime.now() + timedelta(minutes=10),
        "verified": False
    }
    
    success = send_verification_email(req.email, code)
    
    if success:
        return {
            "message": "ì¸ì¦ ì½”ë“œê°€ ì´ë©”ì¼ë¡œ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤",
            "email": req.email,
            "dev_mode": not bool(SMTP_EMAIL),
            "code": code if not SMTP_EMAIL else None
        }
    else:
        raise HTTPException(500, "ì´ë©”ì¼ ë°œì†¡ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤")

class VerifyCodeRequest(BaseModel):
    email: EmailStr
    code: str

@app.post("/auth/verify-code")
async def verify_code(req: VerifyCodeRequest):
    """ì¸ì¦ ì½”ë“œ í™•ì¸"""
    if req.email not in verification_codes:
        raise HTTPException(400, "ì¸ì¦ ì½”ë“œê°€ ë°œì†¡ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    stored = verification_codes[req.email]
    
    if datetime.now() > stored["expires_at"]:
        del verification_codes[req.email]
        raise HTTPException(400, "ì¸ì¦ ì½”ë“œê°€ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ë°œì†¡í•´ì£¼ì„¸ìš”")
    
    if stored["code"] != req.code:
        raise HTTPException(400, "ì¸ì¦ ì½”ë“œê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
    
    verification_codes[req.email]["verified"] = True
    
    return {
        "message": "ì´ë©”ì¼ ì¸ì¦ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤",
        "verified": True,
        "email": req.email
    }

@app.post("/auth/register", response_model=Token)
async def register(user_data: UserCreate):
    """íšŒì›ê°€ì… - ì´ë©”ì¼ ì¸ì¦ í•„ìš”"""
    if get_user_by_email(user_data.email):
        raise HTTPException(400, "ì´ë¯¸ ë“±ë¡ëœ ì´ë©”ì¼ì…ë‹ˆë‹¤")
    
    # ì´ë©”ì¼ ì¸ì¦ í™•ì¸
    if user_data.email not in verification_codes:
        raise HTTPException(400, "ì´ë©”ì¼ ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤. ë¨¼ì € ì¸ì¦ ì½”ë“œë¥¼ ë°œì†¡í•´ì£¼ì„¸ìš”")
    
    if not verification_codes[user_data.email].get("verified"):
        raise HTTPException(400, "ì´ë©”ì¼ ì¸ì¦ì´ ì™„ë£Œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    
    # ì¸ì¦ ì„±ê³µ í›„ ì½”ë“œ ì‚­ì œ
    del verification_codes[user_data.email]
    
    is_valid, message = validate_password_strength(user_data.password)
    if not is_valid:
        raise HTTPException(400, message)
    
    user = create_user(user_data)
    access_token = create_access_token({"sub": user.email})
    
    return Token(access_token=access_token, token_type="bearer", user=user)

@app.post("/auth/login", response_model=Token)
async def login(credentials: UserLogin):
    """ë¡œê·¸ì¸"""
    check_rate_limit(credentials.email)
    
    user_dict = get_user_by_email(credentials.email)
    if not user_dict or not user_dict.get("hashed_password"):
        raise HTTPException(401, "ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    if not verify_password(credentials.password, user_dict["hashed_password"]):
        raise HTTPException(401, "ì´ë©”ì¼ ë˜ëŠ” ë¹„ë°€ë²ˆí˜¸ê°€ ì˜ëª»ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    access_token = create_access_token({"sub": user_dict["email"]})
    user = User(**{k: v for k, v in user_dict.items() if k != "hashed_password"})
    
    return Token(access_token=access_token, token_type="bearer", user=user)

@app.get("/auth/google")
async def google_auth(request: Request):
    if not GOOGLE_CLIENT_ID:
        raise HTTPException(400, "Google OAuth not configured")
    redirect_uri = request.url_for('google_auth_callback')
    return await oauth.google.authorize_redirect(request, redirect_uri)

@app.get("/auth/google/callback")
async def google_auth_callback(request: Request):
    try:
        token = await oauth.google.authorize_access_token(request)
        user_info = token.get('userinfo')
        
        if user_info:
            user_dict = get_user_by_email(user_info['email'])
            if user_dict:
                user = User(**{k: v for k, v in user_dict.items() if k != "hashed_password"})
            else:
                user = create_oauth_user(
                    user_info['email'],
                    user_info['name'],
                    user_info.get('picture')
                )
            
            access_token = create_access_token({"sub": user.email})
            return RedirectResponse(url=f"/?token={access_token}&user={user.email}")
    except Exception as e:
        print(f"Google auth error: {e}")
        return RedirectResponse(url="/login.html?error=auth_failed")

@app.get("/auth/me")
async def get_me(current_user: User = Depends(get_current_user)):
    return current_user

# ===== í”„ë¡œí•„ API =====

@app.get("/users/profile")
async def get_profile(current_user: User = Depends(get_current_user)):
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM user_profiles WHERE user_id = ?", (current_user.id,))
        row = cursor.fetchone()
        return dict(row) if row else UserProfile().model_dump()

@app.post("/users/profile")
async def set_profile(profile: UserProfile, current_user: User = Depends(get_current_user)):
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
        UPDATE user_profiles 
        SET risk=?, budget=?, goal=?, interest_field=?, experience_level=?
        WHERE user_id=?
        ''', (profile.risk, profile.budget, profile.goal, 
              profile.interest_field, profile.experience_level, current_user.id))
        conn.commit()
    return {"ok": True, "profile": profile}

@app.post("/chat/save")
async def save_chat_session(chat_request: SaveChatRequest, current_user: User = Depends(get_current_user)):
    """ì±„íŒ… ê¸°ë¡ ì €ì¥"""
    try:
        chat_storage_key = f"chat_history_{current_user.email}"
        
        # ê¸°ì¡´ ì±„íŒ… ê¸°ë¡ ë¶ˆëŸ¬ì˜¤ê¸°
        existing_chats = redis_client.get(chat_storage_key)
        if existing_chats:
            chat_history = json.loads(existing_chats)
        else:
            chat_history = []
        
        # ìƒˆ ì±„íŒ… ì„¸ì…˜ ì¶”ê°€
        new_chat = {
            "id": str(datetime.now().timestamp()),
            "user_email": current_user.email,
            "timestamp": datetime.now().isoformat(),
            "messages": [msg.dict() for msg in chat_request.messages]
        }
        
        chat_history.append(new_chat)
        
        # ìµœê·¼ 50ê°œ ì±„íŒ…ë§Œ ì €ì¥ (ë©”ëª¨ë¦¬ ê´€ë¦¬)
        if len(chat_history) > 50:
            chat_history = chat_history[-50:]
        
        # Redisì— ì €ì¥
        redis_client.set(chat_storage_key, json.dumps(chat_history))
        
        return {"status": "success", "message": "Chat saved successfully"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to save chat: {str(e)}")

@app.get("/chat/history")
async def get_chat_history(current_user: User = Depends(get_current_user)):
    """ì±„íŒ… ê¸°ë¡ ì¡°íšŒ"""
    try:
        chat_storage_key = f"chat_history_{current_user.email}"
        
        existing_chats = redis_client.get(chat_storage_key)
        if existing_chats:
            chat_history = json.loads(existing_chats)
            # ìµœì‹  ì±„íŒ…ì´ ë¨¼ì € ì˜¤ë„ë¡ ì •ë ¬
            chat_history.sort(key=lambda x: x['timestamp'], reverse=True)
            return chat_history
        else:
            return []
            
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to load chat history: {str(e)}")

@app.delete("/chat/{chat_id}")
async def delete_chat_session(chat_id: str, current_user: User = Depends(get_current_user)):
    """ì±„íŒ… ê¸°ë¡ ì‚­ì œ"""
    try:
        chat_storage_key = f"chat_history_{current_user.email}"
        
        existing_chats = redis_client.get(chat_storage_key)
        if existing_chats:
            chat_history = json.loads(existing_chats)
            # í•´ë‹¹ ì±„íŒ… ì‚­ì œ
            chat_history = [chat for chat in chat_history if chat['id'] != chat_id]
            
            # Redisì— ì—…ë°ì´íŠ¸
            redis_client.set(chat_storage_key, json.dumps(chat_history))
            
        return {"status": "success", "message": "Chat deleted successfully"}
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=f"Failed to delete chat: {str(e)}")

# ===== RAG API =====

# ===== JSONL íŒŒì¼ ê´€ë¦¬ (ë°±ì—…/í˜¸í™˜ì„±ìš©) =====

DOCS_JSONL_PATH = os.path.join(os.path.dirname(DB_PATH), "docs.jsonl")

def load_jsonl_docs() -> List[Dict[str, Any]]:
    """JSONL íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ"""
    if not os.path.exists(DOCS_JSONL_PATH):
        return []
    
    docs = []
    try:
        with open(DOCS_JSONL_PATH, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line:
                    docs.append(json.loads(line))
    except Exception as e:
        print(f"JSONL ë¡œë“œ ì˜¤ë¥˜: {e}")
    
    return docs

def save_jsonl_docs(docs: List[Dict[str, Any]]):
    """JSONL íŒŒì¼ì— ë¬¸ì„œ ì €ì¥ (ë®ì–´ì“°ê¸°)"""
    try:
        with open(DOCS_JSONL_PATH, "w", encoding="utf-8") as f:
            for doc in docs:
                f.write(json.dumps(doc, ensure_ascii=False) + "\n")
    except Exception as e:
        print(f"JSONL ì €ì¥ ì˜¤ë¥˜: {e}")

def clean_jsonl_duplicates(keep_latest: int = 1):
    """
    docs.jsonlì—ì„œ ì¤‘ë³µ URL ì •ë¦¬
    keep_latest: URLë‹¹ ìœ ì§€í•  ìµœì‹  ë¬¸ì„œ ê°œìˆ˜
    """
    docs = load_jsonl_docs()
    
    if not docs:
        return 0, 0
    
    # URLë³„ë¡œ ê·¸ë£¹í™”
    url_groups = {}
    for doc in docs:
        url = doc.get("url", "")
        if url not in url_groups:
            url_groups[url] = []
        url_groups[url].append(doc)
    
    # ê° URLë³„ë¡œ ìµœì‹  ìˆœìœ¼ë¡œ ì •ë ¬ í›„ í•„ìš”í•œ ê°œìˆ˜ë§Œ ìœ ì§€
    cleaned_docs = []
    total_before = len(docs)
    
    for url, doc_list in url_groups.items():
        # as_of_date ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬ (ìµœì‹ ìˆœ)
        sorted_docs = sorted(
            doc_list, 
            key=lambda x: x.get("as_of_date", "1970-01-01"),
            reverse=True
        )
        
        # ìµœì‹  Nê°œë§Œ ìœ ì§€
        cleaned_docs.extend(sorted_docs[:keep_latest])
    
    # íŒŒì¼ì— ë®ì–´ì“°ê¸°
    save_jsonl_docs(cleaned_docs)
    
    total_after = len(cleaned_docs)
    deleted = total_before - total_after
    
    return deleted, total_after

def sync_db_to_jsonl():
    """SQLite DBì˜ ë¬¸ì„œë¥¼ JSONLì— ë™ê¸°í™” (ë°±ì—…)"""
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM documents ORDER BY created_at DESC")
        rows = cursor.fetchall()
        
        docs = []
        for row in rows:
            doc_dict = dict(row)
            # created_atì„ as_of_dateë¡œ ë³€í™˜
            doc_dict['as_of_date'] = doc_dict.get('created_at', now_date())
            docs.append(doc_dict)
        
        save_jsonl_docs(docs)
        return len(docs)

@app.post("/maintenance/cleanup-jsonl")
async def cleanup_jsonl(
    keep_per_url: int = 1,
    current_user: User = Depends(get_current_user)
):
    """
    docs.jsonl íŒŒì¼ ì •ë¦¬
    keep_per_url: URLë‹¹ ìœ ì§€í•  ë¬¸ì„œ ê°œìˆ˜
    """
    deleted, remaining = clean_jsonl_duplicates(keep_latest=keep_per_url)
    
    return {
        "deleted": deleted,
        "remaining": remaining,
        "keep_per_url": keep_per_url,
        "message": f"{deleted}ê°œ ë¬¸ì„œ ì‚­ì œ, {remaining}ê°œ ë¬¸ì„œ ìœ ì§€ë¨"
    }

@app.post("/maintenance/sync-db-to-jsonl")
async def sync_to_jsonl(current_user: User = Depends(get_current_user)):
    """SQLite DB ë‚´ìš©ì„ JSONL íŒŒì¼ë¡œ ë°±ì—…"""
    count = sync_db_to_jsonl()
    return {
        "synced": count,
        "message": f"{count}ê°œ ë¬¸ì„œê°€ JSONL íŒŒì¼ë¡œ ë°±ì—…ë˜ì—ˆìŠµë‹ˆë‹¤"
    }

@app.delete("/maintenance/delete-jsonl")
async def delete_jsonl_file(current_user: User = Depends(get_current_user)):
    """docs.jsonl íŒŒì¼ ì™„ì „ ì‚­ì œ"""
    if os.path.exists(DOCS_JSONL_PATH):
        os.remove(DOCS_JSONL_PATH)
        return {"message": "JSONL íŒŒì¼ì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤"}
    return {"message": "JSONL íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}

def clean_old_documents_by_url(url: str, keep_latest: int = 1):
    """
    ê°™ì€ URLì˜ ì˜¤ë˜ëœ ë¬¸ì„œ ì‚­ì œ (DBì—ì„œ)
    keep_latest: ìœ ì§€í•  ìµœì‹  ë¬¸ì„œ ê°œìˆ˜ (ê¸°ë³¸ 1ê°œ)
    """
    with get_db() as conn:
        cursor = conn.cursor()
        
        # í•´ë‹¹ URLì˜ ëª¨ë“  ë¬¸ì„œë¥¼ ë‚ ì§œìˆœìœ¼ë¡œ ì¡°íšŒ
        cursor.execute('''
        SELECT id, created_at FROM documents 
        WHERE url = ? 
        ORDER BY created_at DESC
        ''', (url,))
        
        docs = cursor.fetchall()
        
        if len(docs) <= keep_latest:
            return 0  # ì‚­ì œí•  ë¬¸ì„œ ì—†ìŒ
        
        # ìœ ì§€í•  ë¬¸ì„œ ì œì™¸í•˜ê³  ë‚˜ë¨¸ì§€ ì‚­ì œ
        docs_to_delete = [dict(d)["id"] for d in docs[keep_latest:]]
        
        if docs_to_delete:
            placeholders = ','.join('?' * len(docs_to_delete))
            cursor.execute(f'''
            DELETE FROM documents 
            WHERE id IN ({placeholders})
            ''', docs_to_delete)
            
            conn.commit()
            return len(docs_to_delete)
        
        return 0

def rebuild_index_from_db():
    """ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì „ì²´ ì¸ë±ìŠ¤ ì¬êµ¬ì¶•"""
    global _texts, _metas, _index, _bm25
    
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute("SELECT * FROM documents ORDER BY created_at DESC")
        rows = cursor.fetchall()
        
        if not rows:
            _texts = []
            _metas = []
            _index = None
            _bm25 = None
            return
        
        _texts = [dict(r)["text"] for r in rows]
        _metas = [{k: dict(r)[k] for k in ["id", "title", "url", "as_of_date", "source", "category"]} 
                 for r in rows]
        
        # BM25 ì¬êµ¬ì¶•
        _bm25 = BM25Okapi([t.split() for t in _texts])
        
        # FAISS ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
        vecs = encode_texts(_texts)
        _index = build_index(vecs)

@app.post("/ingest")
async def ingest(req: IngestReq, current_user: User = Depends(get_current_user)):
    global _texts, _metas, _index, _bm25
    
    if not req.urls:
        raise HTTPException(400, "URLsê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
    
    items = []
    urls_processed = []
    deleted_count = 0
    
    for url in req.urls:
        try:
            title, body = fetch_url(url, use_js=req.use_js)
            
            # ê°™ì€ URLì˜ ì˜¤ë˜ëœ ë¬¸ì„œ ì‚­ì œ
            deleted = clean_old_documents_by_url(url, keep_latest=0)
            deleted_count += deleted
            
            for chunk in chunk_text(body):
                doc_id = str(uuid.uuid4())
                items.append({
                    "id": doc_id,
                    "user_id": current_user.id,
                    "source": req.source,
                    "category": "ì¡°ê°íˆ¬ì",
                    "title": title,
                    "section": "ë³¸ë¬¸",
                    "url": url,
                    "as_of_date": now_date(),
                    "text": chunk
                })
            
            urls_processed.append(url)
            
        except Exception as e:
            print(f"URL ì²˜ë¦¬ ì‹¤íŒ¨ {url}: {e}")
            continue
    
    if not items:
        raise HTTPException(400, "í¬ë¡¤ë§ ì‹¤íŒ¨")
    
    # DBì— ìƒˆ ë¬¸ì„œ ì €ì¥
    with get_db() as conn:
        cursor = conn.cursor()
        for item in items:
            cursor.execute('''
            INSERT INTO documents (id, user_id, source, category, title, section, url, as_of_date, text)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (item["id"], item["user_id"], item["source"], item["category"],
                  item["title"], item["section"], item["url"], item["as_of_date"], item["text"]))
        conn.commit()
    
    # ì „ì²´ ì¸ë±ìŠ¤ ì¬êµ¬ì¶• (ì‚­ì œëœ ë¬¸ì„œ ë°˜ì˜)
    rebuild_index_from_db()
    
    return {
        "added": len(items), 
        "deleted": deleted_count,
        "urls_processed": urls_processed,
        "total": len(_texts),
        "message": f"{len(items)}ê°œ ë¬¸ì„œ ì¶”ê°€, {deleted_count}ê°œ ì˜¤ë˜ëœ ë¬¸ì„œ ì‚­ì œë¨"
    }


def build_user_prompt(question: str, passages: List[Dict], risk: str, budget: int, goal: str, interest_field: str = "ë¶€ë™ì‚°, ì˜ˆìˆ , ìŒì•…", experience_level: str = "ì´ˆë³´ì") -> str:
    """ì‚¬ìš©ì ì§ˆë¬¸ + ê²€ìƒ‰ëœ ë¬¸ì„œ + íˆ¬ì ì„±í–¥ â†’ LLM í”„ë¡¬í”„íŠ¸"""
    context_lines = []
    for i, p in enumerate(passages, start=1):
        txt = p.get("text", "")
        context_lines.append(f"[{i}] {txt}")
    
    context_str = "\n".join(context_lines) if context_lines else "(ê´€ë ¨ ë¬¸ì„œ ì—†ìŒ)"
    
    prompt = f"""[ì‚¬ìš©ì ì„±í–¥]
ë¦¬ìŠ¤í¬ ì„ í˜¸: {risk}
íˆ¬ì ì˜ˆì‚°: {budget:,}ì›
íˆ¬ì ëª©í‘œ: {goal}
ê´€ì‹¬ ë¶„ì•¼: {interest_field}
íˆ¬ì ê²½í—˜: {experience_level}

[ê²€ìƒ‰ëœ ë¬¸ì„œ]
{context_str}

[ì§ˆë¬¸]
{question}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì‚¬ìš©ìì˜ íˆ¬ì ì„±í–¥(ë¦¬ìŠ¤í¬, ì˜ˆì‚°, ëª©í‘œ, ê´€ì‹¬ ë¶„ì•¼, ê²½í—˜)ì„ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì—¬ ì¡°ê°íˆ¬ì ê´€ì ì—ì„œ ë§ì¶¤í˜• ë‹µë³€í•´ì£¼ì„¸ìš”.
íŠ¹íˆ ì˜ˆì‚°, ë¦¬ìŠ¤í¬ ìˆ˜ì¤€, ëª©í‘œ, ê´€ì‹¬ ë¶„ì•¼ì— ë§ëŠ” ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì •ë³´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""
    
    return prompt


@app.post("/query", response_model=QueryRes)
async def query(req: QueryReq, current_user: User = Depends(get_current_user)):
    # ë¬¸ì„œê°€ ì—†ì–´ë„ ë‹µë³€ ê°€ëŠ¥
    passages = []
    
    if _texts and _index is not None:
        try:
            cand = vec_search(req.question, k=req.k)
            topk = bm25_rerank(req.question, cand, k=req.k)
            
            for i in topk:
                if 0 <= i < len(_texts):
                    passages.append({**_metas[i], "text": _texts[i]})
        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ì§„í–‰): {e}")
    
    # í”„ë¡œí•„ ê°€ì ¸ì˜¤ê¸° - í•­ìƒ í”„ë¡œí•„ì„ ì ìš©
    profile = await get_profile(current_user)
    
    # ìš”ì²­ì— ëª…ì‹œëœ ê°’ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ í”„ë¡œí•„ ê°’ ì‚¬ìš©
    risk = req.risk if req.risk and req.risk != "ì¤‘ê°„" else profile.get("risk", "ì¤‘ê°„")
    budget = req.budget if req.budget and req.budget != 1_000_000 else profile.get("budget", 1_000_000)
    goal = req.goal if req.goal and req.goal != "ë‹¨ê¸°í˜„ê¸ˆíë¦„" else profile.get("goal", "ë‹¨ê¸°í˜„ê¸ˆíë¦„")
    interest_field = profile.get("interest_field", "ë¶€ë™ì‚°, ì˜ˆìˆ , ìŒì•…")
    experience_level = profile.get("experience_level", "ì´ˆë³´ì")
    
    # ë¬¸ì„œê°€ ìˆìœ¼ë©´ RAG, ì—†ìœ¼ë©´ ì¼ë°˜ ë‹µë³€
    if passages:
        prompt = build_user_prompt(req.question, passages, risk, budget, goal, interest_field, experience_level)
    else:
        prompt = f"""[ì‚¬ìš©ì ì„±í–¥]
ë¦¬ìŠ¤í¬ ì„ í˜¸: {risk}
íˆ¬ì ì˜ˆì‚°: {budget:,}ì›
íˆ¬ì ëª©í‘œ: {goal}
ê´€ì‹¬ ë¶„ì•¼: {interest_field}
íˆ¬ì ê²½í—˜: {experience_level}

[ì§ˆë¬¸]
{req.question}

ìœ„ ì‚¬ìš©ìì˜ íˆ¬ì ì„±í–¥ì„ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì—¬ ì¡°ê°íˆ¬ì ì „ë¬¸ê°€ë¡œì„œ ë§ì¶¤í˜• ë‹µë³€ì„ ì œê³µí•´ì£¼ì„¸ìš”. 
íŠ¹íˆ ì‚¬ìš©ìì˜ ë¦¬ìŠ¤í¬ ìˆ˜ì¤€, ì˜ˆì‚°, ëª©í‘œ, ê´€ì‹¬ ë¶„ì•¼, ê²½í—˜ ìˆ˜ì¤€ì— ì í•©í•œ êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ í¬í•¨í•´ì£¼ì„¸ìš”."""
    
    answer = call_openai(prompt, LLM_SYSTEM_PROMPT)
    
    # íˆìŠ¤í† ë¦¬ ì €ì¥
    with get_db() as conn:
        cursor = conn.cursor()
        cursor.execute('''
        INSERT INTO chat_history (id, user_id, question, answer)
        VALUES (?, ?, ?, ?)
        ''', (str(uuid.uuid4()), current_user.id, req.question, answer))
        conn.commit()
    
    sources = [{"n": j+1, "title": p["title"], "url": p["url"]} 
               for j, p in enumerate(passages)]
    
    return QueryRes(
        answer=answer,
        backend=f"OpenAI Â· {OPENAI_MODEL}",
        k=len(passages),
        sources=sources
    )

# ===== ë¬¸ì„œ ê´€ë¦¬ API =====

@app.get("/documents")
async def list_documents(
    current_user: User = Depends(get_current_user),
    limit: int = 50,
    offset: int = 0
):
    """ì‚¬ìš©ìì˜ ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # ì „ì²´ ê°œìˆ˜
        cursor.execute('''
        SELECT COUNT(DISTINCT url) FROM documents WHERE user_id = ?
        ''', (current_user.id,))
        total = cursor.fetchone()[0]
        
        # URLë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ìµœì‹  ë¬¸ì„œë§Œ ì¡°íšŒ
        cursor.execute('''
        SELECT 
            url,
            title,
            source,
            category,
            MAX(created_at) as latest_created,
            COUNT(*) as chunk_count
        FROM documents 
        WHERE user_id = ?
        GROUP BY url
        ORDER BY latest_created DESC
        LIMIT ? OFFSET ?
        ''', (current_user.id, limit, offset))
        
        docs = [dict(row) for row in cursor.fetchall()]
    
    return {
        "total": total,
        "documents": docs,
        "limit": limit,
        "offset": offset
    }

@app.delete("/documents/url")
async def delete_documents_by_url(
    url: str,
    current_user: User = Depends(get_current_user)
):
    """íŠ¹ì • URLì˜ ëª¨ë“  ë¬¸ì„œ ì‚­ì œ"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # ì‚­ì œí•  ë¬¸ì„œ ê°œìˆ˜ í™•ì¸
        cursor.execute('''
        SELECT COUNT(*) FROM documents 
        WHERE url = ? AND user_id = ?
        ''', (url, current_user.id))
        
        count = cursor.fetchone()[0]
        
        if count == 0:
            raise HTTPException(404, "í•´ë‹¹ URLì˜ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        
        # ì‚­ì œ ì‹¤í–‰
        cursor.execute('''
        DELETE FROM documents 
        WHERE url = ? AND user_id = ?
        ''', (url, current_user.id))
        
        conn.commit()
    
    # ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
    rebuild_index_from_db()
    
    return {
        "deleted": count,
        "url": url,
        "total_remaining": len(_texts)
    }

@app.delete("/documents/all")
async def delete_all_documents(current_user: User = Depends(get_current_user)):
    """ì‚¬ìš©ìì˜ ëª¨ë“  ë¬¸ì„œ ì‚­ì œ"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        cursor.execute('''
        SELECT COUNT(*) FROM documents WHERE user_id = ?
        ''', (current_user.id,))
        count = cursor.fetchone()[0]
        
        cursor.execute('''
        DELETE FROM documents WHERE user_id = ?
        ''', (current_user.id,))
        
        conn.commit()
    
    # ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
    rebuild_index_from_db()
    
    return {
        "deleted": count,
        "total_remaining": len(_texts)
    }

@app.post("/documents/cleanup")
async def cleanup_old_documents(
    keep_per_url: int = 1,
    current_user: User = Depends(get_current_user)
):
    """
    ì¤‘ë³µ URL ì •ë¦¬ - URLë‹¹ ìµœì‹  Nê°œë§Œ ìœ ì§€
    keep_per_url: URLë‹¹ ìœ ì§€í•  ë¬¸ì„œ ê°œìˆ˜ (ê¸°ë³¸ 1)
    """
    with get_db() as conn:
        cursor = conn.cursor()
        
        # ì‚¬ìš©ìì˜ ëª¨ë“  URL ì¡°íšŒ
        cursor.execute('''
        SELECT DISTINCT url FROM documents WHERE user_id = ?
        ''', (current_user.id,))
        
        urls = [row[0] for row in cursor.fetchall()]
        
        total_deleted = 0
        cleaned_urls = []
        
        for url in urls:
            # ê° URLë³„ë¡œ ì˜¤ë˜ëœ ë¬¸ì„œ ì‚­ì œ
            cursor.execute('''
            SELECT id, created_at FROM documents 
            WHERE url = ? AND user_id = ?
            ORDER BY created_at DESC
            ''', (url, current_user.id))
            
            docs = cursor.fetchall()
            
            if len(docs) > keep_per_url:
                # ìœ ì§€í•  ë¬¸ì„œ ì œì™¸í•˜ê³  ì‚­ì œ
                docs_to_delete = [dict(d)["id"] for d in docs[keep_per_url:]]
                
                placeholders = ','.join('?' * len(docs_to_delete))
                cursor.execute(f'''
                DELETE FROM documents WHERE id IN ({placeholders})
                ''', docs_to_delete)
                
                total_deleted += len(docs_to_delete)
                cleaned_urls.append({
                    "url": url,
                    "deleted": len(docs_to_delete),
                    "kept": keep_per_url
                })
        
        conn.commit()
    
    # ì¸ë±ìŠ¤ ì¬êµ¬ì¶•
    rebuild_index_from_db()
    
    return {
        "total_deleted": total_deleted,
        "cleaned_urls": cleaned_urls,
        "total_remaining": len(_texts)
    }

@app.get("/documents/stats")
async def document_stats(current_user: User = Depends(get_current_user)):
    """ë¬¸ì„œ í†µê³„ ì •ë³´"""
    with get_db() as conn:
        cursor = conn.cursor()
        
        # ì „ì²´ ë¬¸ì„œ ìˆ˜
        cursor.execute('''
        SELECT COUNT(*) FROM documents WHERE user_id = ?
        ''', (current_user.id,))
        total_docs = cursor.fetchone()[0]
        
        # ê³ ìœ  URL ìˆ˜
        cursor.execute('''
        SELECT COUNT(DISTINCT url) FROM documents WHERE user_id = ?
        ''', (current_user.id,))
        unique_urls = cursor.fetchone()[0]
        
        # ì†ŒìŠ¤ë³„ í†µê³„
        cursor.execute('''
        SELECT source, COUNT(*) as count 
        FROM documents 
        WHERE user_id = ?
        GROUP BY source
        ''', (current_user.id,))
        by_source = [{"source": row[0], "count": row[1]} for row in cursor.fetchall()]
        
        # ì¤‘ë³µ URL ì •ë³´
        cursor.execute('''
        SELECT url, COUNT(*) as count
        FROM documents
        WHERE user_id = ?
        GROUP BY url
        HAVING count > 1
        ORDER BY count DESC
        ''', (current_user.id,))
        duplicates = [{"url": row[0], "count": row[1]} for row in cursor.fetchall()]
        
    return {
        "total_documents": total_docs,
        "unique_urls": unique_urls,
        "average_per_url": round(total_docs / unique_urls, 2) if unique_urls > 0 else 0,
        "by_source": by_source,
        "duplicate_urls": duplicates,
        "duplicate_count": len(duplicates)
    }

@app.get("/health")
def health():
    return {
        "status": "ok",
        "db": "SQLite",
        "docs": len(_texts),
        "backend": f"OpenAI Â· {OPENAI_MODEL}"
    }

@app.get("/stats")
def stats():
    return {"docs": len(_texts)}

# ===== HTML í˜ì´ì§€ =====

@app.get("/", response_class=HTMLResponse)
@app.get("/index.html", response_class=HTMLResponse)
def read_root():
    try:
        with open("index.html", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return RedirectResponse(url="/docs")

@app.get("/login.html", response_class=HTMLResponse)
def read_login():
    try:
        with open("login.html", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return HTMLResponse("<h1>Login Page</h1><a href='/auth/google'>Google Login</a>")
    

@app.get("/register.html", response_class=HTMLResponse)
def read_register():
    try:
        with open("register.html", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return HTMLResponse("<h1>Register Page</h1><p>register.html íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”</p>")

@app.get("/app.html", response_class=HTMLResponse)
def read_app():
    try:
        with open("app.html", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return {"error": "app.html not found"}
    
@app.get("/features.html", response_class=HTMLResponse)
def read_features():
    try:
        with open("features.html", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return HTMLResponse("<h1>Features</h1>")

@app.get("/about.html", response_class=HTMLResponse)
def read_about():
    try:
        with open("about.html", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return HTMLResponse("<h1>About</h1>")

@app.get("/profile.html", response_class=HTMLResponse)
def read_profile():
    try:
        with open("profile.html", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return HTMLResponse("<h1>Profile</h1><p>profile.html íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”</p>")

@app.get("/how-it-works.html", response_class=HTMLResponse)
def read_how_it_works():
    try:
        with open("how-it-works.html", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return HTMLResponse("<h1>How it works</h1>")
    
@app.get("/profile-history.html", response_class=HTMLResponse)
def read_profile_history():
    try:
        with open("profile-history.html", "r", encoding="utf-8") as f:
            return f.read()
    except:
        return HTMLResponse("<h1>í”„ë¡œí•„ ê¸°ë¡ í˜ì´ì§€</h1><p>profile-history.html íŒŒì¼ì„ ìƒì„±í•´ì£¼ì„¸ìš”</p>")   

@app.get("/main.css")
async def read_main_css():
    try:
        with open("main.css", "r", encoding="utf-8") as f:
            css_content = f.read()
            return Response(
                content=css_content, 
                media_type="text/css; charset=utf-8",
                headers={
                    "Cache-Control": "public, max-age=3600",
                    "Content-Type": "text/css; charset=utf-8"
                }
            )
    except Exception as e:
        print(f"âŒ CSS ë¡œë“œ ì‹¤íŒ¨: {e}")
        return Response(
            content="/* main.css not found */", 
            media_type="text/css; charset=utf-8"
        )

@app.get("/app.css")
async def read_app_css():
    try:
        with open("app.css", "r", encoding="utf-8") as f:
            css_content = f.read()
            return Response(
                content=css_content, 
                media_type="text/css; charset=utf-8",
                headers={
                    "Cache-Control": "public, max-age=3600",
                    "Content-Type": "text/css; charset=utf-8"
                }
            )
    except Exception as e:
        print(f"âŒ CSS ë¡œë“œ ì‹¤íŒ¨: {e}")
        return Response(
            content="/* app.css not found */", 
            media_type="text/css; charset=utf-8"
        )

@app.get("/favicon.ico")
def favicon():
    return Response(status_code=204)

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("api_v6:app", host="0.0.0.0", port=8000, reload=True)